{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13dc265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awast\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0001760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8ba22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_graph():\n",
    "#     src=[]\n",
    "#     end=[]\n",
    "#     for i in range(25):\n",
    "#         for j in range(25):\n",
    "#             src.append(i)\n",
    "#             end.append(j)\n",
    "#     g= dgl.graph((np.array(src),np.array(end)),num_nodes=25)\n",
    "#     return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7782585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g=make_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3fb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707da6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0841095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train0=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\distilbert_single\\\\distil_train.npy\",allow_pickle=True)\n",
    "# x_dev0=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\distilbert_single\\\\distil_dev.npy\", allow_pickle=True)\n",
    "# x_test0=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\distilbert_single\\\\distil_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98f84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\CJPE-main\\\\Models\\\\Sequential_Models\\\\train_embedding.npy\",allow_pickle=True)\n",
    "dev_emb=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\CJPE-main\\\\Models\\\\Sequential_Models\\\\dev_embedding.npy\",allow_pickle=True)\n",
    "test_emb=np.load(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\CJPE-main\\\\Models\\\\Sequential_Models\\\\test_emb.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa41eab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1, 1, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84bbb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### x_train0[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f52ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.31835768, -0.36139387,  0.35681376, ...,  0.14843127,\n",
       "           0.3317359 , -0.1260191 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.35004267, -0.3440218 ,  0.3587354 , ...,  0.1211519 ,\n",
       "           0.277878  , -0.0922926 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.37070134, -0.3570638 ,  0.33644882, ...,  0.18024248,\n",
       "           0.30940834, -0.1198357 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.2742787 , -0.37066177,  0.31463698, ...,  0.11083905,\n",
       "           0.324626  , -0.14297026]]],\n",
       "\n",
       "\n",
       "       [[[-0.3004411 , -0.35565805,  0.2789553 , ...,  0.12079363,\n",
       "           0.300907  , -0.09504852]]],\n",
       "\n",
       "\n",
       "       [[[-0.25744554, -0.3840833 ,  0.26039726, ...,  0.10724942,\n",
       "           0.25847912, -0.13985352]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f482ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND']='pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1135fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embeddings(train0, dev0, test0):\n",
    "    train=[]\n",
    "    dev=[]\n",
    "    test=[]\n",
    "    for i in range(train0.shape[0]):\n",
    "        emb=np.zeros((25,200))\n",
    "        numb=train0[i].shape[0]\n",
    "        for j in range(train0[i].shape[0]):\n",
    "            emb[j]=train0[i][j][0][0]\n",
    "        train.append(emb)\n",
    "    \n",
    "    for i in range(dev0.shape[0]):\n",
    "        emb=np.zeros((25,200))\n",
    "        numb=dev0[i].shape[0]\n",
    "        for j in range(dev0[i].shape[0]):\n",
    "#             emb[j]=train0[i][j][0][0]    \n",
    "            emb[j]=dev0[i][j][0][0]\n",
    "        dev.append(emb)\n",
    "    \n",
    "    for i in range(test0.shape[0]):\n",
    "        emb=np.zeros((25,200))\n",
    "        numb=test0[i].shape[0]\n",
    "        for j in range(test0[i].shape[0]):\n",
    "#             emb[j]=train0[i][j][0][0]    \n",
    "#             emb[j]=dev0[i][j][0][0]    \n",
    "            emb[j]=test0[i][j][0][0] \n",
    "        test.append(emb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.array(train), np.array(dev), np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08bbfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test=make_embeddings(train_emb,dev_emb,test_emb)\n",
    "# train, dev, test=make_embeddings(x_train0,x_dev0,x_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce526b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g=g.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e047e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7a8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.ndata['features']=torch.from_numpy(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3dc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.ndata['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4258688d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22389334,  0.07000541,  0.35366666, ..., -0.00747715,\n",
       "        -0.04536502, -0.32923865],\n",
       "       [-0.13675033, -0.1687728 ,  0.15040742, ..., -0.13759632,\n",
       "        -0.26088887, -0.33238328],\n",
       "       [-0.14374441,  0.04491721,  0.23605536, ...,  0.00348465,\n",
       "        -0.04624036, -0.33855921],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e0a42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kgcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08431f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d51b1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91bf97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c668aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\n",
    "#     'https://data.dgl.ai/tutorial/dataset/graph_edges.csv', './graph_edges.csv')\n",
    "# urllib.request.urlretrieve(\n",
    "#     'https://data.dgl.ai/tutorial/dataset/graph_properties.csv', './graph_properties.csv')\n",
    "# edges = pd.read_csv('./graph_edges.csv')\n",
    "# properties = pd.read_csv('./graph_properties.csv')\n",
    "\n",
    "# edges.head()\n",
    "\n",
    "# properties.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fa0344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(x_train0):\n",
    "    data1={'graph_id':[],'src':[],'dst':[]}\n",
    "    data= pd.DataFrame(data1)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    for i in range(x_train0.shape[0]):\n",
    "        #print(i)\n",
    "        for j in range(25):\n",
    "            for k in range(25):\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "                z.append(k)\n",
    "                #data = data.append(df2, ignore_index = True)\n",
    "                #data.loc[len(data.index)] = [i, j, k]\n",
    "                \n",
    "    data = {'graph_id': x, 'src': y, 'dst': z}\n",
    "    data=pd.DataFrame(data)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "338d5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph=make_dataset(train_emb)\n",
    "test_graph=make_dataset(test_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff58a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\awast\\\\Desktop\\\\NLP\\\\Data\\\\Data\\\\ILDC_single\\\\ILDC_single\\\\ILDC_single.csv\\\\ILDC_single.csv\")\n",
    "train_set = df.query(\" split=='train' \")\n",
    "validation_set = df.query(\" split=='dev' \")\n",
    "test_set = df.query(\" split=='test' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4030ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5082    1\n",
       "5083    0\n",
       "5084    0\n",
       "5085    0\n",
       "5086    1\n",
       "       ..\n",
       "6594    1\n",
       "6595    0\n",
       "6596    1\n",
       "6597    1\n",
       "6598    1\n",
       "Name: label, Length: 1517, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ff82ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_labels(train_set):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    for i in range(train_set.shape[0]):\n",
    "        #print(i)\n",
    "        \n",
    "        x.append(i)\n",
    "        y.append(train_set['label'][i])\n",
    "        z.append(25)\n",
    "                #data = data.append(df2, ignore_index = True)\n",
    "                #data.loc[len(data.index)] = [i, j, k]\n",
    "                \n",
    "    properties = {'graph_id': x, 'label': y, 'num_nodes': z}\n",
    "    properties=pd.DataFrame(properties)\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0d1a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_properties=make_dataset_labels(train_set)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b36e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_labels(test_set):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    for i in range(test_set.shape[0]):\n",
    "        #print(i)\n",
    "        \n",
    "        x.append(i)\n",
    "        y.append(test_set['label'][i+5082])\n",
    "        z.append(25)\n",
    "                #data = data.append(df2, ignore_index = True)\n",
    "                #data.loc[len(data.index)] = [i, j, k]\n",
    "                \n",
    "    properties = {'graph_id': x, 'label': y, 'num_nodes': z}\n",
    "    properties=pd.DataFrame(properties)\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c39598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_properties=make_dataset_labels(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353a39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "859549bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        edges = train_graph\n",
    "        properties = train_properties\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        for _, row in properties.iterrows():\n",
    "            label_dict[row['graph_id']] = row['label']\n",
    "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = edges.groupby('graph_id')\n",
    "\n",
    "        # For each graph ID...\n",
    "        for graph_id in edges_group.groups:\n",
    "            # Find the edges as well as the number of nodes and its label.\n",
    "            edges_of_id = edges_group.get_group(graph_id)\n",
    "            src = edges_of_id['src'].to_numpy()\n",
    "            dst = edges_of_id['dst'].to_numpy()\n",
    "            num_nodes = num_nodes_dict[graph_id]\n",
    "            label = label_dict[graph_id]\n",
    "\n",
    "            # Create a graph and add it to the list of graphs and labels.\n",
    "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
    "            g.ndata['feat']=torch.from_numpy(train[graph_id])      #torch.from_numpy(train[graph_id])\n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        # Convert the label list to tensor for saving.\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f5c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38462389",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SyntheticDataset()\n",
    "\n",
    "\n",
    "# graph, label = dataset[0]\n",
    "# print(graph, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e73ca0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset2(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        edges = test_graph\n",
    "        properties = test_properties\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        for _, row in properties.iterrows():\n",
    "            label_dict[row['graph_id']] = row['label']\n",
    "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = edges.groupby('graph_id')\n",
    "\n",
    "        # For each graph ID...\n",
    "        for graph_id in edges_group.groups:\n",
    "            # Find the edges as well as the number of nodes and its label.\n",
    "            edges_of_id = edges_group.get_group(graph_id)\n",
    "            src = edges_of_id['src'].to_numpy()\n",
    "            dst = edges_of_id['dst'].to_numpy()\n",
    "            num_nodes = num_nodes_dict[graph_id]\n",
    "            label = label_dict[graph_id]\n",
    "\n",
    "            # Create a graph and add it to the list of graphs and labels.\n",
    "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
    "            g.ndata['feat']=torch.from_numpy(test[graph_id])\n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        # Convert the label list to tensor for saving.\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5d3d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset= SyntheticDataset2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1f32496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42ef2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fbca80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=25, num_edges=625,\n",
       "      ndata_schemes={'feat': Scheme(shape=(200,), dtype=torch.float64)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144fc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b26afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import DenseGraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats1,h_feats2,h_feats3, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats1)\n",
    "#         self.conv2 = GraphConv(in_feats, h_feats2)\n",
    "#         self.conv1_2=GraphConv(h_feats1, h_feats1)\n",
    "#         self.conv1_3=GraphConv(h_feats1, h_feats2)\n",
    "#         self.conv1_4=GraphConv(h_feats2, h_feats3)\n",
    "        self.conv2 = GraphConv(h_feats1, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "\n",
    "#         h=self.conv1_2(g,h)\n",
    "#         h = F.relu(h)\n",
    "        \n",
    "#         h=self.conv1_3(g,h)\n",
    "#         h = F.relu(h)\n",
    "        \n",
    "#         h=self.conv1_4(g,h)\n",
    "#         h = F.relu(h)\n",
    "        \n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata[\"h\"] = h\n",
    "        return dgl.mean_nodes(g, \"h\")\n",
    "\n",
    "# g_model = GCN(200, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c88c347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "# num_examples = len(dataset)\n",
    "# num_train = int(num_examples * 0.8)\n",
    "\n",
    "# # train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "# test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    train_dataset, batch_size=12, drop_last=False\n",
    ")\n",
    "test_dataloader = GraphDataLoader(\n",
    "    test_dataset, batch_size=12, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bac0d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db71262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e73347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch Loss: tensor(109.9984, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.908805031446541\n",
      "Epoch:  1\n",
      "Epoch Loss: tensor(91.1214, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9209905660377359\n",
      "Epoch:  2\n",
      "Epoch Loss: tensor(86.0968, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9259040880503144\n",
      "Epoch:  3\n",
      "Epoch Loss: tensor(83.4595, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9282625786163522\n",
      "Epoch:  4\n",
      "Epoch Loss: tensor(81.8374, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9304245283018868\n",
      "Epoch:  5\n",
      "Epoch Loss: tensor(80.7581, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9310141509433962\n",
      "Epoch:  6\n",
      "Epoch Loss: tensor(79.9855, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.932193396226415\n",
      "Epoch:  7\n",
      "Epoch Loss: tensor(79.3955, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9318003144654088\n",
      "Epoch:  8\n",
      "Epoch Loss: tensor(78.9215, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9321933962264151\n",
      "Epoch:  9\n",
      "Epoch Loss: tensor(78.5275, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9323899371069182\n",
      "Epoch:  10\n",
      "Epoch Loss: tensor(78.1829, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9327830188679245\n",
      "Epoch:  11\n",
      "Epoch Loss: tensor(77.8838, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  12\n",
      "Epoch Loss: tensor(77.6007, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484275\n",
      "Epoch:  13\n",
      "Epoch Loss: tensor(77.3456, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289307\n",
      "Epoch:  14\n",
      "Epoch Loss: tensor(77.1190, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9327830188679245\n",
      "Epoch:  15\n",
      "Epoch Loss: tensor(76.9037, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  16\n",
      "Epoch Loss: tensor(76.6860, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  17\n",
      "Epoch Loss: tensor(76.4763, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9323899371069182\n",
      "Epoch:  18\n",
      "Epoch Loss: tensor(76.2743, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  19\n",
      "Epoch Loss: tensor(76.0917, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484277\n",
      "Epoch:  20\n",
      "Epoch Loss: tensor(75.8851, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  21\n",
      "Epoch Loss: tensor(75.6796, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9335691823899372\n",
      "Epoch:  22\n",
      "Epoch Loss: tensor(75.4602, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289307\n",
      "Epoch:  23\n",
      "Epoch Loss: tensor(75.2201, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  24\n",
      "Epoch Loss: tensor(74.9830, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933569182389937\n",
      "Epoch:  25\n",
      "Epoch Loss: tensor(74.6314, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  26\n",
      "Epoch Loss: tensor(74.2716, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933569182389937\n",
      "Epoch:  27\n",
      "Epoch Loss: tensor(73.9216, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484277\n",
      "Epoch:  28\n",
      "Epoch Loss: tensor(73.5857, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484276\n",
      "Epoch:  29\n",
      "Epoch Loss: tensor(73.2415, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484276\n",
      "Epoch:  30\n",
      "Epoch Loss: tensor(72.9028, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289309\n",
      "Epoch:  31\n",
      "Epoch Loss: tensor(72.5494, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484276\n",
      "Epoch:  32\n",
      "Epoch Loss: tensor(72.2425, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9327830188679245\n",
      "Epoch:  33\n",
      "Epoch Loss: tensor(71.9103, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9337657232704402\n",
      "Epoch:  34\n",
      "Epoch Loss: tensor(71.6829, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484277\n",
      "Epoch:  35\n",
      "Epoch Loss: tensor(71.3449, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933569182389937\n",
      "Epoch:  36\n",
      "Epoch Loss: tensor(71.1031, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289307\n",
      "Epoch:  37\n",
      "Epoch Loss: tensor(70.9116, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9329795597484276\n",
      "Epoch:  38\n",
      "Epoch Loss: tensor(70.6573, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9327830188679245\n",
      "Epoch:  39\n",
      "Epoch Loss: tensor(70.4854, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9321933962264151\n",
      "Epoch:  40\n",
      "Epoch Loss: tensor(70.2816, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874214\n",
      "Epoch:  41\n",
      "Epoch Loss: tensor(70.0993, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9327830188679245\n",
      "Epoch:  42\n",
      "Epoch Loss: tensor(70.0508, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  43\n",
      "Epoch Loss: tensor(69.8995, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9325864779874213\n",
      "Epoch:  44\n",
      "Epoch Loss: tensor(69.7029, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  45\n",
      "Epoch Loss: tensor(69.5944, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  46\n",
      "Epoch Loss: tensor(69.5416, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289307\n",
      "Epoch:  47\n",
      "Epoch Loss: tensor(69.4621, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  48\n",
      "Epoch Loss: tensor(69.2568, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9331761006289307\n",
      "Epoch:  49\n",
      "Epoch Loss: tensor(69.1873, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9337657232704403\n",
      "Epoch:  50\n",
      "Epoch Loss: tensor(69.1476, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  51\n",
      "Epoch Loss: tensor(69.0929, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9335691823899372\n",
      "Epoch:  52\n",
      "Epoch Loss: tensor(68.9988, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9337657232704403\n",
      "Epoch:  53\n",
      "Epoch Loss: tensor(68.8785, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9337657232704402\n",
      "Epoch:  54\n",
      "Epoch Loss: tensor(68.8225, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314465\n",
      "Epoch:  55\n",
      "Epoch Loss: tensor(68.7461, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9337657232704402\n",
      "Epoch:  56\n",
      "Epoch Loss: tensor(68.6491, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314465\n",
      "Epoch:  57\n",
      "Epoch Loss: tensor(68.5497, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314467\n",
      "Epoch:  58\n",
      "Epoch Loss: tensor(68.4455, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  59\n",
      "Epoch Loss: tensor(68.3364, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  60\n",
      "Epoch Loss: tensor(68.2167, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933372641509434\n",
      "Epoch:  61\n",
      "Epoch Loss: tensor(68.1654, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.933569182389937\n",
      "Epoch:  62\n",
      "Epoch Loss: tensor(68.1224, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314465\n",
      "Epoch:  63\n",
      "Epoch Loss: tensor(67.9871, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9347484276729561\n",
      "Epoch:  64\n",
      "Epoch Loss: tensor(67.9223, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  65\n",
      "Epoch Loss: tensor(67.8788, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  66\n",
      "Epoch Loss: tensor(67.8166, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314465\n",
      "Epoch:  67\n",
      "Epoch Loss: tensor(67.7662, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314467\n",
      "Epoch:  68\n",
      "Epoch Loss: tensor(67.6510, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9339622641509434\n",
      "Epoch:  69\n",
      "Epoch Loss: tensor(67.6092, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9349449685534592\n",
      "Epoch:  70\n",
      "Epoch Loss: tensor(67.5828, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  71\n",
      "Epoch Loss: tensor(67.5060, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314465\n",
      "Epoch:  72\n",
      "Epoch Loss: tensor(67.4546, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  73\n",
      "Epoch Loss: tensor(67.2813, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  74\n",
      "Epoch Loss: tensor(67.2200, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  75\n",
      "Epoch Loss: tensor(67.2948, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9343553459119497\n",
      "Epoch:  76\n",
      "Epoch Loss: tensor(67.2458, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  77\n",
      "Epoch Loss: tensor(67.1575, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  78\n",
      "Epoch Loss: tensor(67.0525, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  79\n",
      "Epoch Loss: tensor(67.0212, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9341588050314467\n",
      "Epoch:  80\n",
      "Epoch Loss: tensor(66.9682, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  81\n",
      "Epoch Loss: tensor(66.8459, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934944968553459\n",
      "Epoch:  82\n",
      "Epoch Loss: tensor(66.7546, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934944968553459\n",
      "Epoch:  83\n",
      "Epoch Loss: tensor(66.7677, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934944968553459\n",
      "Epoch:  84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: tensor(66.6460, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9349449685534592\n",
      "Epoch:  85\n",
      "Epoch Loss: tensor(66.5614, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  86\n",
      "Epoch Loss: tensor(66.4910, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  87\n",
      "Epoch Loss: tensor(66.4142, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  88\n",
      "Epoch Loss: tensor(66.3840, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9343553459119496\n",
      "Epoch:  89\n",
      "Epoch Loss: tensor(66.3900, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  90\n",
      "Epoch Loss: tensor(66.3316, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  91\n",
      "Epoch Loss: tensor(66.2522, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9353380503144654\n",
      "Epoch:  92\n",
      "Epoch Loss: tensor(66.1717, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  93\n",
      "Epoch Loss: tensor(66.1690, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9345518867924528\n",
      "Epoch:  94\n",
      "Epoch Loss: tensor(66.0251, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9349449685534592\n",
      "Epoch:  95\n",
      "Epoch Loss: tensor(66.0799, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  96\n",
      "Epoch Loss: tensor(66.0515, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9351415094339622\n",
      "Epoch:  97\n",
      "Epoch Loss: tensor(65.9436, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Epoch:  98\n",
      "Epoch Loss: tensor(65.8588, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.9351415094339622\n",
      "Epoch:  99\n",
      "Epoch Loss: tensor(65.7474, grad_fn=<AddBackward0>)\n",
      "epoch_accuracy: 0.934748427672956\n",
      "Test accuracy: 0.6862228081740277\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "train_loss_values = []\n",
    "train_accuracy = []\n",
    "val_loss_values = []\n",
    "val_accuracy = []\n",
    "\n",
    "model = GCN(200,50,50,16, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler=ReduceLROnPlateau(optimizer,mode='min',patience=3,verbose=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_loss=0\n",
    "    train_batch_accuracy = 0\n",
    "    print(\"Epoch: \",epoch)\n",
    "    epoch_loss=0\n",
    "    epoch_acc=[]\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"feat\"].float())\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss\n",
    "        batch_logits = pred\n",
    "        logits = batch_logits.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        train_batch_accuracy = flat_accuracy(logits, label_ids)\n",
    "        epoch_acc.append(train_batch_accuracy)\n",
    "#         print(\"Training Loss:\", loss)\n",
    "    scheduler.step(epoch_loss)\n",
    "    print(\"Epoch Loss:\" ,epoch_loss)\n",
    "    print(\"epoch_accuracy:\", np.array(epoch_acc).mean())\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata[\"feat\"].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print(\"Test accuracy:\", num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b25d37f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6862228081740277\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "test_labels=[]\n",
    "predictions=[]\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph.to(device), batched_graph.ndata[\"feat\"].float().to(device))\n",
    "    predictions+=(pred.argmax(1).cpu().numpy().tolist())\n",
    "    test_labels+=(labels.tolist())\n",
    "    num_correct += (pred.argmax(1) == labels.to(device)).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print(\"Test accuracy:\", num_correct / num_tests)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def calculate_f1(pred,labels):\n",
    "#     metric = BinaryF1Score(multidim_average='samplewise')\n",
    "    return f1_score(labels, pred, average='macro')\n",
    "f1_score=calculate_f1((np.array(predictions)),(np.array(test_labels)))\n",
    "\n",
    "print(\"F1-Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a63d0739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517\n"
     ]
    }
   ],
   "source": [
    "print(num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4e0caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"GRU_GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07da3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"BiGRU_GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e90270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
